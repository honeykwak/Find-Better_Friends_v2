# 데이터 파이프라인 가이드

이 문서는 `public/data`에 있는 최종 애플리케이션 데이터를 생성하기 위한 전체 과정을 안내합니다. 파일명 앞의 번호는 권장되는 작업 순서를 나타냅니다.

---

### **프로세스 요약**

1.  **계획 수립 (`1_OPTIMIZATION_PLAN.md`):** 초기 데이터 최적화 목표와 계획을 확인합니다.
2.  **위험 분석 (`2_ANALYSIS_AND_RISKS.md`):** 초기 계획의 문제점을 파악하고, `category_summary.json` 파일의 필요성을 이해합니다.
3.  **데이터 생성 (`scripts/3_optimizeData.js`):** 원본 CSV 데이터로부터 최종 JSON 파일들을 생성합니다.
4.  **결과 확인:** 생성된 데이터가 애플리케이션에서 정상적으로 사용되는지 확인합니다.

---

### **단계별 상세 가이드**

#### **1단계: 계획 이해**

*   **파일:** `1_OPTIMIZATION_PLAN.md`
*   **내용:** 애플리케이션의 성능 문제를 해결하기 위해 기존의 거대한 단일 데이터 파일을 어떻게 작고 정규화된 여러 파일로 분리할 것인지에 대한 초기 계획을 담고 있습니다.

#### **2단계: 위험 요소 및 보완 사항 확인**

*   **파일:** `2_ANALYSIS_AND_RISKS.md`
*   **내용:** 초기 계획만으로는 필터 패널(`FilterPanel`)의 핵심 기능(카테고리별 통계)이 동작하지 않는 심각한 문제를 식별합니다. 이 문제를 해결하기 위해 사전 계산된 통계 요약 파일인 `category_summary.json`의 생성이 필수적임을 설명합니다.

#### **3단계: 최종 데이터 생성 스크립트 실행**

*   **파일:** `scripts/3_optimizeData.js`
*   **역할:** 이 Node.js 스크립트는 데이터 파이프라인의 핵심입니다.
*   **입력 (Input):** `public/new_data/` 디렉토리에 있는 원본 CSV 파일들.
    *   `proposal_categories_enhanced.csv`: 제안 제목과 카테고리를 매핑하는 정보.
    *   `*_proposals.csv`: 각 체인별 제안 및 투표 원본 데이터.
*   **처리 과정:**
    1.  CSV 파일들을 읽습니다.
    2.  제안, 검증인, 투표, 카테고리 요약 정보를 추출하고 정제합니다.
    3.  이전 버그들을 모두 수정한 로직에 따라 데이터를 올바른 형식으로 가공합니다.
*   **출력 (Output):** `public/data/{chain_name}/` 디렉토리에 체인별로 4개의 JSON 파일을 생성합니다.
    *   `proposals.json`
    *   `validators.json`
    *   `votes.json`
    *   `category_summary.json`
*   **실행 방법:**
    ```bash
    node scripts/3_optimizeData.js
    ```
    이 명령어를 프로젝트 루트 디렉토리에서 실행하면 `public/data` 폴더의 모든 내용이 최신 데이터로 다시 생성됩니다.

---

이 가이드를 통해 데이터 관련 문제를 해결하거나 새로운 데이터를 추가할 때 일관된 방식으로 작업을 수행할 수 있습니다.
